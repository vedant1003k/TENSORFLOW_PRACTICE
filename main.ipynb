{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "NAME = \"Cats-vs-dogs-64x2-CNN\"\n",
    "\n",
    "\n",
    "#  cmd tensorboard --logdir=logs/\n",
    "\n",
    "#specifiing fraction of gpu \n",
    "# Tensorflow 1x\n",
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "print(len(X))\n",
    "\n",
    "\n",
    "# Convert to NumPy arrays or TensorFlow Tensors if needed\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "# OR\n",
    "X = tf.convert_to_tensor(X)\n",
    "y = tf.convert_to_tensor(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALISING T DATA\n",
    "easiest way is to scale the data \n",
    "in our case we are using imaginary data \n",
    "and we know the max and min value that is 255 and 0\n",
    "so divide by 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL IS TRAINED AND SAVED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "546/546 [==============================] - 59s 106ms/step - loss: 0.6228 - accuracy: 0.6484 - val_loss: 0.5675 - val_accuracy: 0.7066\n",
      "Epoch 2/10\n",
      "546/546 [==============================] - 58s 106ms/step - loss: 0.5308 - accuracy: 0.7351 - val_loss: 0.5255 - val_accuracy: 0.7436\n",
      "Epoch 3/10\n",
      "546/546 [==============================] - 57s 104ms/step - loss: 0.4842 - accuracy: 0.7688 - val_loss: 0.4949 - val_accuracy: 0.7620\n",
      "Epoch 4/10\n",
      "546/546 [==============================] - 58s 106ms/step - loss: 0.4475 - accuracy: 0.7917 - val_loss: 0.4777 - val_accuracy: 0.7692\n",
      "Epoch 5/10\n",
      "546/546 [==============================] - 58s 107ms/step - loss: 0.4139 - accuracy: 0.8090 - val_loss: 0.4756 - val_accuracy: 0.7766\n",
      "Epoch 6/10\n",
      "546/546 [==============================] - 59s 108ms/step - loss: 0.3825 - accuracy: 0.8273 - val_loss: 0.4493 - val_accuracy: 0.7894\n",
      "Epoch 7/10\n",
      "546/546 [==============================] - 58s 107ms/step - loss: 0.3482 - accuracy: 0.8497 - val_loss: 0.4765 - val_accuracy: 0.7813\n",
      "Epoch 8/10\n",
      "546/546 [==============================] - 57s 105ms/step - loss: 0.3092 - accuracy: 0.8655 - val_loss: 0.4763 - val_accuracy: 0.7814\n",
      "Epoch 9/10\n",
      "546/546 [==============================] - 57s 105ms/step - loss: 0.2683 - accuracy: 0.8860 - val_loss: 0.4981 - val_accuracy: 0.7928\n",
      "Epoch 10/10\n",
      "546/546 [==============================] - 57s 104ms/step - loss: 0.2296 - accuracy: 0.9056 - val_loss: 0.4967 - val_accuracy: 0.7897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ca7191b490>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))  #lay3\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n","After compiling the code for the first time, make sure to save the model using the 
         provided code snippet. This will prevent the need for repeated training.","\n",
    "model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3,callbacks=[tensorboard])\n",
    "\n",
    "\n",
    "\n",
    "# model.save('trained_model')\n",
    "\n",
    "# new_model=tf.keras.models.load_model('trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 168ms/step\n",
      "[[1.7580239e-29]]\n",
      "Dog\n"
     ]
    }
   ],
   "source": [
    "CATEGORIES = [\"Dog\",\"Cat\"]\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_S=50\n",
    "    img_array = cv.imread(filepath,cv.IMREAD_GRAYSCALE)\n",
    "    new_array = cv.resize(img_array,(IMG_S,IMG_S))\n",
    "    return new_array.reshape(-1,IMG_S,IMG_S,1)\n",
    "\n",
    "new_model=tf.keras.models.load_model('trained_model')\n",
    "\n",
    "prediction = new_model.predict([prepare('test/test_dog3.webp')])\n",
    "print(prediction) # will be a list in a list\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMISING USING TENSOR BOARD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " so wihtout the dense lay3 it evalution val is much better epochs=20\n",
    "\n",
    "out sample should be better than in sample for better model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convolutional and maxpooling goes together\n",
    " specifies that you want to add a 2D convolutional layer with 64 filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINIG MODEL\n",
    "\n",
    "--Create a Sequential model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "--Add the first convolutional layer\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=x.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "-- Add the second convolutional layer\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "--Flatten the output from convolutional layers\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "--- Add a fully connected layer\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "-- Add the output layer for binary classification\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "-- Compile the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(learning_rate=0.001),  # You can adjust the learning rate\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "-- Train the model\n",
    "\n",
    "history = model.fit(x, y, batch_size=32, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
